import os
import pandas as pd
import numpy as np
from dotenv import load_dotenv
from FAP.cloud import CloudManager
from FAP.embedder import FapSearchEngine
# ThÃªm import cho toxic content detection (optional)
def is_toxic(query):
    try:
        from transformers import pipeline
        toxic_classifier = pipeline("text-classification", model="unitary/toxic-bert")
        result = toxic_classifier(query)
        return any(r['label'] == 'toxic' and r['score'] > 0.6 for r in result)
    except:
        # Náº¿u khÃ´ng cÃ i Ä‘áº·t transformers, bá» qua toxic detection
        return False

# Äáº£m báº£o load Ä‘Ãºng file .env á»Ÿ gá»‘c project
ROOT_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
load_dotenv()

# ÄÆ°á»ng dáº«n tuyá»‡t Ä‘á»‘i tá»›i thÆ° má»¥c data/FAP
DATA_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'data', 'FAP'))

def clean_csv_nan_to_placeholder(csv_path, placeholder="unknown"):
    df = pd.read_csv(csv_path)
    df = df.fillna(placeholder)
    df.to_csv(csv_path, index=False, encoding="utf-8-sig")

if __name__ == "__main__":
    print("\nğŸ”‘ Äáº£m báº£o Ä‘Ã£ cáº¥u hÃ¬nh .env vá»›i thÃ´ng tin cloud MySQL Aiven vÃ  Qdrant!")
    # 1. Sync dá»¯ liá»‡u lÃªn cloud
    csv_paths = {
        "student_profile": os.path.join(DATA_DIR, "student_profile.csv"),
        "attendance_reports": os.path.join(DATA_DIR, "attendance_reports.csv"),
        "grade_details": os.path.join(DATA_DIR, "grade_details.csv"),
        "course_summaries": os.path.join(DATA_DIR, "course_summaries.csv")
    }
    for path in csv_paths.values():
        clean_csv_nan_to_placeholder(path)
    db_config = {
    "host": os.environ.get("MYSQL_HOST"),
    "port": int(os.environ.get("MYSQL_PORT", 19116)),
    "user": os.environ.get("MYSQL_USER"),
    "password": os.environ.get("MYSQL_PASSWORD"),
    "db": os.environ.get("MYSQL_DB"),
    "charset": "utf8mb4"
    }
    manager = CloudManager(csv_paths, db_config)
    # === CÃ€O Dá»® LIá»†U FAP ===
    should_scrape = input("Báº¡n cÃ³ muá»‘n cÃ o láº¡i dá»¯ liá»‡u tá»« FAP khÃ´ng? (y/n): ").strip().lower()
    if should_scrape == 'y':
        from FAP import fap_scraper
        gmail = input("Nháº­p email FPT cá»§a báº¡n: ")
        password = input("Nháº­p máº­t kháº©u FPT: ")
        scraper = fap_scraper.FapScraper(gmail=gmail, password=password)
        results = scraper.full_scraping_process()
        if not results:
            print("âŒ Lá»—i khi cÃ o dá»¯ liá»‡u tá»« FAP. Vui lÃ²ng kiá»ƒm tra láº¡i thÃ´ng tin Ä‘Äƒng nháº­p hoáº·c thá»­ láº¡i sau.")
            exit(1)
        # LÆ°u ra CSV Ä‘Ãºng header
        profile = results.get('profile')
        if profile:
            df_profile = pd.DataFrame([profile])
            df_profile.to_csv(csv_paths["student_profile"], index=False, encoding="utf-8-sig")
        attendance = results.get('attendance', [])
        if attendance:
            df_att = pd.DataFrame(attendance)
            df_att.to_csv(csv_paths["attendance_reports"], index=False, encoding="utf-8-sig")
        grade_details = results.get('grade_details', [])
        if grade_details:
            df_grade = pd.DataFrame(grade_details)
            df_grade.to_csv(csv_paths["grade_details"], index=False, encoding="utf-8-sig")
        course_summaries = results.get('course_summaries', [])
        if course_summaries:
            df_course = pd.DataFrame(course_summaries)
            df_course.to_csv(csv_paths["course_summaries"], index=False, encoding="utf-8-sig")
        print("âœ… ÄÃ£ cÃ o vÃ  lÆ°u dá»¯ liá»‡u ra 4 file CSV!")
        # Clean CSV files before cloud sync
        print("ğŸ§¹ Äang lÃ m sáº¡ch dá»¯ liá»‡u CSV...")
        manager.clean_all_csvs()
        manager.create_tables()
        manager.load_dataframes()
        manager.sync_all()
        print("\nğŸ¯ ÄÃ£ lÆ°u toÃ n bá»™ dá»¯ liá»‡u scrape thá»±c táº¿ lÃªn cloud MySQL Aiven!")

    # 2. KÃ©o dá»¯ liá»‡u tá»« cloud vá» local CSVs
    print("\nâ¬‡ï¸ Äang táº£i dá»¯ liá»‡u tá»« cloud vá» local CSVs...")
    manager.download_dataframes()
    # #In ra cÃ¡c df Ä‘Ã£ kÃ©o vá»
    # print(f"File student_profile Ä‘Ã£ kÃ©o vá»: {df_profile}")
    # print(f"File attendance_reports Ä‘Ã£ kÃ©o vá»: {df_att}")
    # print(f"File grade_details Ä‘Ã£ kÃ©o vá»: {df_grade}")
    # print(f"File course_summaries Ä‘Ã£ kÃ©o vá»: {df_course}")
    
    # Clean downloaded CSV files for embedding
    print("ğŸ§¹ Äang lÃ m sáº¡ch dá»¯ liá»‡u CSV cho embedding...")
    manager.clean_all_csvs()

    user_id = input("Nháº­p mÃ£ sinh viÃªn (user_id/roll_number) Ä‘á»ƒ embedding: ")
    df_profile = manager.get_student_df(user_id)
    df_attendance = manager.get_attendance_df(user_id)
    df_grades = manager.get_grades_df(user_id)
    df_courses = manager.get_all_courses_df()

    # LLM Configuration
    enable_llm = input("Báº¡n cÃ³ muá»‘n báº­t LLM Ä‘á»ƒ tá»‘i Æ°u search khÃ´ng? (y/n): ").strip().lower() == 'y'
    if enable_llm:
        print("ğŸ¤– LLM sáº½ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ: extract intent, re-rank results, synthesize answers")
        # print("âš ï¸ Äáº£m báº£o Ä‘Ã£ cáº¥u hÃ¬nh GEMINI_API_KEY trong file .env")
    else:
        print("âš ï¸ LLM disabled - sáº½ dÃ¹ng search embedding truyá»n thá»‘ng")

    qdrant_url = os.environ.get("QDRANT_URL")
    qdrant_api_key = os.environ.get("QDRANT_API_KEY")
    collection_name = os.environ.get("QDRANT_COLLECTION", "Fap_data_testing")
    engine = FapSearchEngine(csv_paths, qdrant_url, qdrant_api_key, collection_name, enable_llm=enable_llm)
    n_embedded = engine.run_full_embedding_pipeline_from_db(user_id, df_profile, df_attendance, df_grades, df_courses)
    print(f"\nğŸ¯ ÄÃ£ embedding vÃ  upsert {n_embedded} payloads má»›i cho user_id {user_id}!")

    # 3. Search terminal
    print("\n=== SEARCH MODE ===")
    if enable_llm and engine.llm_helper and engine.llm_helper.is_available():
        print("ğŸ¤– LLM Search Mode: Intent extraction + Re-ranking + Synthesis enabled")
    else:
        print("ğŸ” Traditional Search Mode: Embedding + Cosine similarity")
    
    # LÆ°u lá»‹ch sá»­ há»™i thoáº¡i
    chat_history = []
    
    while True:
        query = input("\nNháº­p truy váº¥n tÃ¬m kiáº¿m (hoáº·c 'bye' Ä‘á»ƒ thoÃ¡t): ")
        if query.strip().lower() == 'bye':
            print("Táº¡m biá»‡t!")
            break
        
        # Lá»c truy váº¥n Ä‘á»™c háº¡i báº±ng mÃ´ hÃ¬nh AI
        if is_toxic(query):
            print("âš ï¸ Truy váº¥n cá»§a báº¡n cÃ³ ná»™i dung khÃ´ng phÃ¹ há»£p. Vui lÃ²ng sá»­ dá»¥ng ngÃ´n ngá»¯ lá»‹ch sá»±.")
            continue
        
        # ThÃªm truy váº¥n vÃ o chat_history
        chat_history.append({"role": "user", "content": query})
        try:
            results = engine.search_qdrant(query, limit=7, threshold=0.3, chat_history=chat_history)
            if not results:
                print("âŒ KhÃ´ng tÃ¬m tháº¥y káº¿t quáº£ phÃ¹ há»£p. Náº¿u báº¡n cháº¯c cháº¯n Ä‘Ã£ nháº­p Ä‘Ãºng thÃ´ng tin, vui lÃ²ng kiá»ƒm tra láº¡i truy váº¥n hoáº·c liÃªn há»‡ há»— trá»£.")
                chat_history.append({"role": "assistant", "content": "KhÃ´ng tÃ¬m tháº¥y káº¿t quáº£ phÃ¹ há»£p."})
            else:
                print(f"\nğŸ” Top {len(results)} káº¿t quáº£:")
                for r in results:
                    print(f"[{r['rank']}] Score: {r['score']:.3f} | Type: {r['loai']} | Subject: {r['ma_mon_hoc']} - {r['ten_mon_hoc']}\n    {r['content']}\n---")
                # LLM Synthesis (náº¿u enabled)
                if enable_llm and engine.llm_helper and engine.llm_helper.is_available():
                    print("\nğŸ¤– LLM Summary:")
                    summary = engine.llm_helper.synthesize_answer(query, results)
                    if not summary or 'khÃ´ng thá»ƒ tá»•ng há»£p' in summary.lower() or 'khÃ´ng tÃ¬m tháº¥y' in summary.lower():
                        print("KhÃ´ng thá»ƒ tá»•ng há»£p káº¿t quáº£. Vui lÃ²ng xem chi tiáº¿t cÃ¡c káº¿t quáº£ bÃªn trÃªn hoáº·c thá»­ láº¡i truy váº¥n khÃ¡c.")
                        chat_history.append({"role": "assistant", "content": "KhÃ´ng thá»ƒ tá»•ng há»£p káº¿t quáº£."})
                    else:
                        print(summary)
                        chat_history.append({"role": "assistant", "content": summary})
                else:
                    # Náº¿u khÃ´ng dÃ¹ng LLM synthesis, lÆ°u láº¡i káº¿t quáº£ Ä‘áº§u tiÃªn
                    chat_history.append({"role": "assistant", "content": results[0]["content"] if results else ""})
        except Exception as e:
            print(f"âš ï¸ ÄÃ£ xáº£y ra lá»—i khi xá»­ lÃ½ truy váº¥n: {e}\nVui lÃ²ng thá»­ láº¡i sau hoáº·c kiá»ƒm tra káº¿t ná»‘i/API.")
            chat_history.append({"role": "assistant", "content": "ÄÃ£ xáº£y ra lá»—i khi xá»­ lÃ½ truy váº¥n."})