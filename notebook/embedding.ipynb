{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645b6b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "qdrant_api_key = os.getenv(\"qdrant_api_key\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d057f9e2",
   "metadata": {},
   "source": [
    "# Load model embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "977068e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "\n",
    "class BGEEmbedder:\n",
    "    def __init__(self, model_name=\"BAAI/bge-m3\"):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.prefix = \"Represent this sentence for searching relevant passages: \"\n",
    "\n",
    "    def embed(self, texts, batch_size=16):\n",
    "        # BGE-M3 y√™u c·∫ßu prefix cho truy v·∫•n v√† vƒÉn b·∫£n\n",
    "        texts_with_prefix = [\n",
    "            text if text.startswith(self.prefix) else self.prefix + text\n",
    "            for text in texts\n",
    "        ]\n",
    "\n",
    "        # D√πng encode v·ªõi batch size v√† normalize s·∫µn\n",
    "        embeddings = self.model.encode(\n",
    "            texts_with_prefix,\n",
    "            batch_size=batch_size,\n",
    "            normalize_embeddings=True,\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "        return embeddings\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a11166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# # Load model BGE-M3\n",
    "# model = SentenceTransformer(\"BAAI/bge-m3\")\n",
    "\n",
    "# def embed_fn(text: str):\n",
    "#     # BGE-M3 khuy·∫øn ngh·ªã prefix truy v·∫•n b·∫±ng \"Represent this sentence for searching relevant passages:\"\n",
    "#     if not text.startswith(\"Represent\"):\n",
    "#         text = \"Represent this sentence for searching relevant passages: \" + text\n",
    "#     return model.encode(text, normalize_embeddings=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e8b412",
   "metadata": {},
   "source": [
    "# Embedding ph·∫ßn content c·ªßa payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98890a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_payloads_json(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        return json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc05b22f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subject_code': 'OTP101',\n",
       " 'subject_name': 'Orientation and General Training Program_ƒê·ªãnh h∆∞·ªõng v√† R√®n luy·ªán t·∫≠p trung',\n",
       " 'degree_level': 'Bachelor',\n",
       " 'semester': 0,\n",
       " 'credits': 0,\n",
       " 'belong_to_combo': 'nan',\n",
       " 'type': 'overview',\n",
       " 'content': \"TYPE: overview\\nSubject Code: OTP101\\nSubject Name: Orientation and General Training Program_ƒê·ªãnh h∆∞·ªõng v√† R√®n luy·ªán t·∫≠p trung\\nDegree Level: Bachelor | Credits: 0 | Semester: 0\\nBelong To Combo: None\\nPre-requisites: None\\nScoring Scale: 10.0 | Min Avg Mark to Pass: 0.0\\nApproved: True on 8/5/2022\\nSubject Link: https://flm.fpt.edu.vn/gui/role/student/Syllabuses.aspx?subCode=OTP101&curriculumID=2347\\n\\n--- TIME ALLOCATION ---\\n5 weeks (fulltime) = 280 h* Module 1: Orientation-ƒê·ªãnh h∆∞·ªõng(1 week: 8 h/day * 5 days = 40 h)* Module 2: Military Training-Gi√°o d·ª•c qu·ªëc ph√≤ng(110 slots * 1.5 h/slot = 165 h)* Module 3: Experience Program 22 slots * 1.5 h = 33 h* Module 4: Vovinam 28 slots * 1,5 h/slot = 42 h\\n--- TIME ALLOCATION END ---\\n\\n--- DESCRIPTION ---\\n- Orientation and general training program includes 4 modules :* Module 1: Orientation Main activities of this module are:- Organizing the opening ceremony for students.- Organizing health check amd making students' cards.- Arranging classes for students and organizing class meeting.- Introducing to students about FPT corporation, FPT university, functional departments, training regulations and how to use information systems to support students' learning.- Sharing study skills for university students.- Sharing about topics related to community activities. ( For example: activities towards sustainable development, volunteering activities...)* Module 2: Military training the program prescribed by the Ministry of Education and Training.Implementing the program prescribed by the Ministry of Education and Training.* Module 3: Experience program Main activities of this module are:- Organizing research and review memoirs.- Organizing seminars- Organizing experiential activities for students (Towards sustainable development and volunteering for the community)* Module 4: Vovinam Follow the outline VOV 114.Objectives of orientation and training program are:1) Instruct students to complete procedures before a new semester.2) Provide students with knowledge about FPT corporation, FPT university and functional departments which support students during the period of study at the university.3) Introduce to students about Curriculum, FU training model and regulations as well as how to use information systems to enable students to adapt new learning environment.4) Educate students the fundamentals of military and national security, build and enrich patriotism, national pride through history lessons, seminars, documentaries, field trips to military bases and memoirs about two prolonged resistance wars of Viet Nam.5) Train the willpower and improve physical strengths, fitness and sense of responsibilities through physical education lessons and combat practice in the field.6) Train team spirit, disciplines, shape good attitude and behaviors towards friends, teachers and educational environment.7) Enhance student experiences with extra-curricular activities. Strengthen the sense of community through community and volunteering activities and the ones towards the sustainable development.\\n--- END DESCRIPTION ---\\n--- STUDENT TASKS ---\\n- Attend enough activities of the university.\\n--- END STUDENT TASKS ---\\n--- TOOLS ---\\n\\n--- END TOOLS ---\\n--- NOTE ---\\n- Min to pass: Students must pass the examination and achieve the Military training certificate\\n--- END NOTE ---\\n\",\n",
       " 'subject_link': 'https://flm.fpt.edu.vn/gui/role/student/Syllabuses.aspx?subCode=OTP101&curriculumID=2347'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payloads = load_payloads_json(r\"D:\\Learn\\K√¨ 5\\SEG301\\Fap-Chat\\data\\Chunk_JSON\\overview_syllabus_payloads.json\")  \n",
    "payloads[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3201d1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DO TUAN MINH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DO TUAN MINH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "661565f283b84ae39dc52ff7aef74c60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ho·∫∑c load_payloads_json\n",
    "\n",
    "contents = [p[\"content\"] for p in payloads]\n",
    "embedder = BGEEmbedder()               # kh·ªüi t·∫°o instance\n",
    "vectors = embedder.embed(contents)     # g·ªçi method t·ª´ instance\n",
    "\n",
    "\n",
    "\n",
    "# client.upsert(collection_name=\"flm_chunks\", points=points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c76d6f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'overview': 73})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "types = [p[\"type\"] for p in payloads if \"type\" in p]\n",
    "print(Counter(types))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5711db6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.models import PointStruct\n",
    "import uuid\n",
    "\n",
    "points = [\n",
    "    PointStruct(\n",
    "        id=str(uuid.uuid4()),\n",
    "        vector=vec.tolist(),\n",
    "        payload=payload\n",
    "    )\n",
    "    for vec, payload in zip(vectors, payloads)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284b5bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0221aba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03c7161",
   "metadata": {},
   "source": [
    "# G·ªçi Qdrant vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ef1b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance\n",
    "from qdrant_client.models import Filter\n",
    "# client = QdrantClient(\n",
    "#     url=r\"https://0f47d391-b7c1-45d9-a956-5f7228cd80f3.europe-west3-0.gcp.cloud.qdrant.io:6333\",\n",
    "#     api_key=qdrant_api_key,\n",
    "#     prefer_grpc=False\n",
    "# )\n",
    "client = QdrantClient(\n",
    "    host=\"localhost\",\n",
    "    port=6333\n",
    ")\n",
    "\n",
    "# client.recreate_collection(\n",
    "#     collection_name=\"flm_fap\",\n",
    "#     vectors_config=VectorParams(size=1024, distance=Distance.COSINE)\n",
    "# )\n",
    "# client.delete(\n",
    "#     collection_name=\"flm_fap\",\n",
    "#     points_selector=Filter(must=[])  # Xo√° to√†n b·ªô points\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80e94d2",
   "metadata": {},
   "source": [
    "# Up data l√™n vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07ef8251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def safe_upsert(client, collection_name, points, retries=5, wait=5):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            client.upsert(collection_name=collection_name, points=points)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Retry {attempt+1}/{retries} - L·ªói: {e}\")\n",
    "            time.sleep(wait)\n",
    "    return False\n",
    "for i in range(0, len(points), 100):\n",
    "    success = safe_upsert(client, \"flm_fap\", points[i:i+100])\n",
    "    if not success:\n",
    "        print(\"‚ö†Ô∏è Kh√¥ng th·ªÉ upload batch\", i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c409e680",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = client.count(\"flm_fap\", exact=True).count\n",
    "print(f\"‚úÖ S·ªë vector ƒë√£ up: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18247afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = BGEEmbedder()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1230bfb1",
   "metadata": {},
   "source": [
    "# Demo search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1685bf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_flm=pd.read_csv(r'D:\\Learn\\K√¨ 5\\SEG301\\DEMO_local\\FLM\\FINAL_DF_FLM.csv')\n",
    "subject_map = {\n",
    "    row[\"SubjectCode\"]: f\"{row[\"SubjectCode\"]} - {row[\"Subject Name\"]}\"\n",
    "    for _, row in df_flm[[\"SubjectCode\", \"Subject Name\"]].dropna().drop_duplicates().iterrows()\n",
    "}\n",
    "subject_embeddings = {\n",
    "    code: embedder.embed([name])[0]\n",
    "    for code, name in subject_map.items()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e82416",
   "metadata": {},
   "source": [
    "# T·∫°o filter index (mu·ªën t√¨m theo filter ph·∫£i c√≥ c√°i n√†y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe93ebd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=119, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_payload_index(\n",
    "    collection_name=\"flm_fap\",\n",
    "    field_name=\"semester\",\n",
    "    field_schema=\"keyword\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a48120",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.create_payload_index(\n",
    "    collection_name=\"flm_fap\",\n",
    "    field_name=\"subject_code\",\n",
    "    field_schema=\"keyword\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d57fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import heapq\n",
    "def detect_subject(query, top_k=1):\n",
    "    query_vec = embedder.embed([query])[0]\n",
    "    \n",
    "    # T√≠nh cosine similarity v·ªõi t·ª´ng subject\n",
    "    sims = {\n",
    "        code: dot(query_vec, emb) / (norm(query_vec) * norm(emb))\n",
    "        for code, emb in subject_embeddings.items()\n",
    "    }\n",
    "    \n",
    "    # L·∫•y top-k subject code c√≥ ƒëi·ªÉm cao nh·∫•t\n",
    "    top_subjects = heapq.nlargest(top_k, sims.items(), key=lambda x: x[1])\n",
    "    \n",
    "    return top_subjects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1ad8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "def translate_vi_to_en_google(text):\n",
    "    return GoogleTranslator(source='vi', target='en').translate(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f354e452",
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPE_DESCRIPTIONS = {\n",
    "    \"overview\": \"general overview of the subject, goals, credits, syllabus\",\n",
    "    \"construtive_question\": \"thought-provoking questions\",\n",
    "    \"assessment\": \"evaluations, types of tests, exams, and grading weights for the subject\",\n",
    "    \"session\": \"lecture sessions, lessons, schedules, topics covered in each week or session\",\n",
    "    \"material\": \"recommended textbooks, reference materials, slides, or other learning resources\",\n",
    "    \"learning outcome\": \"learning outcome, expected knowledge, skills, or competencies students should achieve after completing the course\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "type_embeddings = {\n",
    "    t: embedder.embed([desc])[0] for t, desc in TYPE_DESCRIPTIONS.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abb35d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # --- Step 0: Optional Translate Query (n·∫øu c·∫ßn)\n",
    "# query = \"t·ªïng quan m√¥n search engine\"\n",
    "\n",
    "# # N·∫øu c√≥ h√†m d·ªãch: query_en = translate_vi_to_en_nllb(query)\n",
    "# query_en = query  # n·∫øu b·∫°n kh√¥ng c·∫ßn d·ªãch ho·∫∑c ƒë√£ l√† ti·∫øng Anh\n",
    "\n",
    "# --- Step 1: Detect type b·∫±ng embedding\n",
    "def detect_type_by_embedding(query_en):\n",
    "    query_vec = embedder.embed([query_en])[0]\n",
    "    sims = {\n",
    "        t: dot(query_vec, vec) / (norm(query_vec) * norm(vec))\n",
    "        for t, vec in type_embeddings.items()\n",
    "    }\n",
    "    best_type = max(sims, key=sims.get)\n",
    "    return best_type \n",
    "\n",
    "# query_type = detect_type_by_embedding(query_en)\n",
    "\n",
    "\n",
    "query = \"learning outcome cho m√¥n deep learning\"\n",
    "# query_en = query  # ho·∫∑c d√πng translate n·∫øu c·∫ßn\n",
    "query_en = translate_vi_to_en_google(query)\n",
    "print(query_en)\n",
    "\n",
    "detected_type = detect_type_by_embedding(query_en)\n",
    "detected_subject = detect_subject(query_en)\n",
    "\n",
    "query_vec = embedder.embed([query])[0]\n",
    "\n",
    "\n",
    "# query_filter = {\"must\": []}\n",
    "# if detected_type:\n",
    "#     query_filter[\"must\"].append({\"key\": \"type\", \"match\": {\"value\": detected_type}})\n",
    "# if detected_subject:\n",
    "#     query_filter[\"must\"].append({\"key\": \"subject_code\", \"match\": {\"value\": detected_subject}})\n",
    "\n",
    "query_filter = {\"should\": [], \"must\":[]}\n",
    "if detected_type:\n",
    "    print(detected_type)\n",
    "    query_filter[\"must\"].append({\"key\": \"type\", \"match\": {\"value\": detected_type}})\n",
    "if detected_subject:\n",
    "    for subject_code in detected_subject:\n",
    "        print(subject_code[0])\n",
    "        query_filter[\"should\"].append({\n",
    "            \"key\": \"subject_code\",\n",
    "            \"match\": {\"value\": subject_code[0]}\n",
    "        })\n",
    "\n",
    "hits = client.search(\n",
    "    collection_name=\"flm_fap\",\n",
    "    query_vector=query_vec.tolist(),\n",
    "    limit=20,\n",
    "    query_filter=query_filter if query_filter[\"must\"] or query_filter[\"should\"] else None\n",
    ")\n",
    "\n",
    "\n",
    "# --- Step 4: Hi·ªÉn th·ªã k·∫øt qu·∫£\n",
    "for hit in hits:\n",
    "    print(f\"\\nüîç Score: {hit.score:.4f}\")\n",
    "    print(f\"üìò Subject: {hit.payload.get('subject_code')} - {hit.payload.get('type')}\")\n",
    "    print(f\"üìÑ Content:\\n{hit.payload.get('content')}\")\n",
    "    print(\"--------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfccaa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Scroll 1000 ƒëi·ªÉm (ho·∫∑c bao nhi√™u c≈©ng ƒë∆∞·ª£c t√πy collection c·ªßa b·∫°n)\n",
    "points, _ = client.scroll(\n",
    "    collection_name=\"flm_fap\",\n",
    "    limit=2621,  # ho·∫∑c nhi·ªÅu h∆°n n·∫øu mu·ªën\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "# L·∫•y t·∫•t c·∫£ c√°c 'type' trong payload\n",
    "type_list = [point.payload.get(\"type\") for point in points if \"type\" in point.payload]\n",
    "\n",
    "# ƒê·∫øm s·ªë l·∫ßn xu·∫•t hi·ªán m·ªói type\n",
    "type_counts = Counter(type_list)\n",
    "\n",
    "# In ra k·∫øt qu·∫£\n",
    "print(\"C√°c type c√≥ trong collection:\")\n",
    "for t, count in type_counts.items():\n",
    "    print(f\"- {t}: {count} b·∫£n ghi\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b505011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç S·ªë l∆∞·ª£ng ƒëi·ªÉm c·∫ßn x√≥a: 65\n",
      "‚úÖ ƒê√£ x√≥a th√†nh c√¥ng.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from qdrant_client.models import PointIdsList\n",
    "\n",
    "# L·∫•y to√†n b·ªô points\n",
    "points = client.scroll(\n",
    "    collection_name=\"flm_fap\",\n",
    "    scroll_filter=None,\n",
    "    limit=10000,\n",
    "    with_payload=True\n",
    ")[0]\n",
    "\n",
    "# L·ªçc c√°c ID c√≥ type l√† 'construtive_question'\n",
    "to_delete = [pt.id for pt in points\n",
    "             if pt.payload.get(\"type\") == \"overview\"]\n",
    "\n",
    "print(f\"üîç S·ªë l∆∞·ª£ng ƒëi·ªÉm c·∫ßn x√≥a: {len(to_delete)}\")\n",
    "\n",
    "# X√≥a n·∫øu c√≥\n",
    "if to_delete:\n",
    "    client.delete(\n",
    "        collection_name=\"flm_fap\",\n",
    "        points_selector=PointIdsList(points=to_delete)\n",
    "    )\n",
    "    print(\"‚úÖ ƒê√£ x√≥a th√†nh c√¥ng.\")\n",
    "else:\n",
    "    print(\"‚úÖ Kh√¥ng t√¨m th·∫•y ƒëi·ªÉm n√†o ƒë·ªÉ x√≥a.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
